{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "13645a6401094b8e9e43ee6439cebbb7",
    "deepnote_cell_type": "markdown"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "2e08b85981b542379983caf1619bceab",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Ideen Use Case\n",
    "- Gesetzbuch ZGB\n",
    "- Kochbuch\n",
    "- LLM Agent generiert Werbetexe, Social Media Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "71dc5b3cd80f444c85229c5a5d134243",
    "deepnote_cell_type": "text-cell-h3",
    "formattedRanges": []
   },
   "source": [
    "### FWO-Assistent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8e372a10361b49d79135bb1ac2bc94e8",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- Hilft bei der Erstellung von Texten für LinkedIn, Instagram, WhatsApp etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "34e39c6b71ff43369582549ea792d7a4",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- Auf Basis von vergangenen Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "48703dda10da4a189aae9e8b27d1da51",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 1312,
    "execution_start": 1759758229079,
    "source_hash": "af9e9b5a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amuel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import langchain\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "LLM_MODEL = \"openai/gpt-oss-20b:free\"\n",
    "LLM_TEMPERATURE = 0.4\n",
    "BASE_URL = \"https://openrouter.ai/api/v1\"\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "USER_PROMPT=\"Generiere mir einen Instagrampost\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "560a2f48c30445d0af462bee57df506a",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 2680,
    "execution_start": 1759758230441,
    "source_hash": "b9f7f98b"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=LLM_MODEL,\n",
    "    temperature=LLM_TEMPERATURE,\n",
    "    base_url=BASE_URL,\n",
    "    api_key=OPENROUTER_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "a39ea2f0cef040f4bc860ac3c41a6a4d",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 0,
    "execution_start": 1759758233169,
    "source_hash": "90dbf177"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "FWO_PROMPT = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"Du bist der FWO-Assistent (Fachschaft Wirtschaft Olten, FHNW). \"\n",
    "     \"Bevor du schreibst, beziehst du dich IMMER auf: \"\n",
    "     \"1) Kampagnenkonzept (Ziel, Kernbotschaft, Mehrwert) \"\n",
    "     \"2) Redaktionsplan (Phase, wiederkehrende Formate, Timing). \"\n",
    "     \"Vermeide Genderung und gebrauche bspw. Lehrperson anstatt Lehrer*innen \"\n",
    "     \"Generiere jeweils immer zwei Vorschläge zu jeder Plattform (Instagram, WhatsApp, LinkedIn)\"\n",
    "     \"Vermeide Floskeln, schreibe aktiv und konkret.\"\n",
    "     \"If you are unsure or the answer isn't in the context, say that you don't know.\\n\\n\"\n",
    "    ),\n",
    "    (\"user\",\n",
    "     \"User: {text}\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "6b201c73c9d040e9af1c979816ae55dd",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 12311,
    "execution_start": 1759758233279,
    "source_hash": "51d1e9bd"
   },
   "outputs": [],
   "source": [
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "user_prompt=\"Generiere mir einen Post für die PubTour am 16. Oktober\"\n",
    "\n",
    "# chain_simple = (FWO_PROMPT | llm | StrOutputParser())\n",
    "# result = chain_simple.invoke(user_prompt)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "2f723a65eeb04432a1ba77dcfe049109",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 483,
    "execution_start": 1759758245649,
    "source_hash": "3195d87f"
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# List of PDF file paths\n",
    "\n",
    "pdf_path = \"Order pdf/SoMe Konzept.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(str(pdf_path))\n",
    "pages = loader.load()\n",
    "\n",
    "\n",
    "# Load all documents\n",
    "# all_pages_pdf = []\n",
    "# for pdf in pdf_files:\n",
    "#     loader = PyPDFLoader(pdf)\n",
    "#     pages = loader.load()\n",
    "#     all_pages_pdf.extend(pages)\n",
    "\n",
    "#print(f\"Loaded {len(all_pages_pdf)} pages from {len(pdf_files)} pdf documents.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "a4a0f6c0e3844ca2a7e68192889aadf3",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 0,
    "execution_start": 1759758246179,
    "source_hash": "600011ae"
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# get both websites and pdfs together\n",
    "all_docs = pages\n",
    "\n",
    "# define the splitter and strategy\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=100)\n",
    "splits = splitter.split_documents(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "c2e805c3427c4dcda39006a9105b2777",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 0,
    "execution_start": 1759758246229,
    "source_hash": "b0d5d671"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial documents: 6\n",
      "Total chunks: 55\n",
      "Avg length: 253.0\n",
      "Min: 48, Max: 297\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "lengths = [len(s.page_content) for s in splits]\n",
    "print(f\"Initial documents: {len(all_docs)}\")\n",
    "print(f\"Total chunks: {len(splits)}\")\n",
    "print(f\"Avg length: {np.mean(lengths):.1f}\")\n",
    "print(f\"Min: {np.min(lengths)}, Max: {np.max(lengths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "92e542040e284e96b3a342fcf5c63bc2",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 18668,
    "execution_start": 1759758246289,
    "source_hash": "cc8d3bbc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amuel\\AppData\\Local\\Temp\\ipykernel_26140\\4293025327.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "276a8ec04dfa486a8eb26443f9c1b7f0",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 11559,
    "execution_start": 1759758265010,
    "source_hash": "65dc8a79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7243b00a-bdf0-4ea8-b689-43797338d9e7',\n",
       " 'ff11b571-354f-479a-a3b3-73deb2b2d980',\n",
       " 'c9a966f4-8b3c-4a86-89fe-6b2e0a380dc9',\n",
       " '44a3a4fb-058d-4545-9cae-db2d56cba617',\n",
       " '972c28e0-8b7e-4d37-a482-004ce498f4fb',\n",
       " '4b7ed638-c79b-4d7f-91a2-078722bb0736',\n",
       " '492ddfd4-8d34-48e1-84a6-a13ce01167c0',\n",
       " '01128f78-4702-44aa-a792-9d1aa2d02f5a',\n",
       " 'e450ae02-a8da-48b4-96c4-3d23fc41fbb9',\n",
       " 'dee28694-91c9-4781-8e98-1c3a99e486c3',\n",
       " '3348f234-1066-4540-bebe-11104d0334e0',\n",
       " 'c031b08e-0522-415e-975c-4ad19f42ae5f',\n",
       " 'd9d3d565-5629-4653-af83-92ccf1cbf24e',\n",
       " '8db6c282-6232-40da-8b45-77f9338a83e8',\n",
       " '2bfde551-4946-4d65-bcf4-53071604ab72',\n",
       " 'e4fa302a-12c4-47af-8230-685c42163f02',\n",
       " 'b3edcca2-9e40-4634-b30e-2cb2ce36857d',\n",
       " '8955e847-d703-474a-a571-e4b6deee3254',\n",
       " '0bdc844f-5364-4170-abc7-08a2713d6e29',\n",
       " '8857d25f-f7a0-4519-a6d9-96f84899b98b',\n",
       " 'fb1b128c-ab34-4183-a355-80696515f7f3',\n",
       " '2c390f75-cb92-4a7e-84f9-978eac2abf39',\n",
       " '006de712-0a81-49bd-8ca2-bd1d898eb22f',\n",
       " '0b2807c3-b48c-4238-80b2-8dd1c770683c',\n",
       " 'b26becc8-81ea-474b-9f03-86ec4731d434',\n",
       " 'd22342f8-abd2-4001-a18e-08fcd4041c58',\n",
       " '5da7ede5-dd3d-47b5-885e-5b167e17ecde',\n",
       " '100aeca5-1a7f-4771-b26e-cef00a8b5f78',\n",
       " '43334902-d2c2-47dc-bc6f-e22d91499b41',\n",
       " '91fd6efa-93b9-4633-bc2c-482f959061ed',\n",
       " 'f0e4c33b-8355-450d-83b7-eecb7d35a787',\n",
       " '0ec419c9-3556-4339-bc6a-d9076b598288',\n",
       " 'd5f7f332-5a89-436d-8930-a51e2aee5af6',\n",
       " 'c334cb20-b1a7-47aa-b5cd-6a7f4b0597c1',\n",
       " '0cae2bf5-995b-4ed0-9e95-f383dc410063',\n",
       " 'd19fae6d-b9d4-481a-bd8f-525c9efb2493',\n",
       " '412e6e8d-95e0-41e4-8afd-8c3b3e4dc50a',\n",
       " '528765ac-5ce8-40a3-a27d-fb77834caf26',\n",
       " 'dea8cc71-ccda-4638-a238-f126d727273d',\n",
       " '6d466bd5-22ae-493e-a2ec-5e7a620ca6f0',\n",
       " 'cadd0d1c-f32f-44d0-a224-2149046b5784',\n",
       " 'd6714cb0-1fec-4af8-ace2-8dea745b937a',\n",
       " 'b7200c61-f017-4b86-ba63-65ba9cd344e7',\n",
       " '1ac80599-475e-4d31-900a-27f0ecfe6388',\n",
       " '9201f5e1-0ab0-45cb-9703-08d602499228',\n",
       " 'e4b37c2d-064c-4113-b71a-fe5af3ec9db2',\n",
       " '614d7da8-7a54-4205-882a-16ce9599d387',\n",
       " '41cc81bd-4f3e-4a05-8982-b6d1fa4904ea',\n",
       " '55192a4d-6d85-40cc-9479-b0ec62895c96',\n",
       " 'cc1377c0-8d9a-435f-9a7a-680a17770dcb',\n",
       " '6fb1bf4a-8fa7-437d-bddd-2b1c270c12e7',\n",
       " '2e1e9526-8aca-49cd-920a-e038f1de7e99',\n",
       " '97e9b023-d2e4-4400-8b9f-95510abca225',\n",
       " 'de6a9a85-c522-44c5-8658-d82696abcacb',\n",
       " 'd2f3a8f5-ba8a-410b-a8c7-199bd37b4417']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embedding_dim = len(embeddings.embed_query(\"hello world\"))\n",
    "index = faiss.IndexFlatL2(embedding_dim)\n",
    "\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    "    normalize_L2=True\n",
    ")\n",
    "\n",
    "vector_store.add_documents(documents=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "39c71595501b4099b86a137eecf48618",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 0,
    "execution_start": 1759758276629,
    "source_hash": "2ca0bc3c"
   },
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "dca3c25d995f4dcaa99e9e38d24247c9",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 1,
    "execution_start": 1759758276689,
    "source_hash": "aa4529ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Retrieved doc 1 ---\n",
      "- Grund: Account aktiv halten vor allem in Zeiten, bei denen weniger Posts gemacht \n",
      "werden können. \n",
      "Hashtags: \n",
      "#FHNW #FWO #FachschaftWirtschaftOlten #HappyEaster #HappyChristmas #HappyXmas und \n",
      "Spezifische Hashtags die von Partnern vorgegeben werden. \n",
      "Standard Seeding: ...\n",
      "\n",
      "--- Retrieved doc 2 ---\n",
      "Hashtags: Keine Hashtags \n",
      "Seeding: kein Seeding. ...\n",
      "\n",
      "--- Retrieved doc 3 ---\n",
      "Die meisten Jugendlichen/jungen Erwachsene sind auf Instagram aktiv. Das Posten von Events \n",
      "auf diesem Kanal ermöglicht der FWO ein gutes und interessantes Image für die FHNW in Olten \n",
      "zu erschaffen und somit zukünftige Studierende zu „überzeugen“ an der FH in Olten studieren zu ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amuel\\AppData\\Local\\Temp\\ipykernel_26140\\3188004710.py:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(\"Hashtags für Instagram\")\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.get_relevant_documents(\"Hashtags für Instagram\")\n",
    "for i, d in enumerate(docs, 1):\n",
    "    print(f\"--- Retrieved doc {i} ---\")\n",
    "    print(d.page_content[:400], \"...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "7628494db79b4133966fb98d4c707ab8",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# chain = (\n",
    "#     {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "#     | FWO_PROMPT\n",
    "#     | llm\n",
    "#     | output_parser\n",
    "# )\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": retriever,     # <- Docs -> Text\n",
    "        \"question\": RunnablePassthrough(),      # <- nimmt den String-Input direkt\n",
    "    }\n",
    "    | FWO_PROMPT\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": "51912f3cb08b43e4b9d485e1821e52ce",
    "deepnote_cell_type": "code",
    "execution_context_id": "117fea94-7943-4067-9a2a-3e8454f791c1",
    "execution_millis": 25790,
    "execution_start": 1759758276799,
    "source_hash": "51d1e9bd"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# from langchain_core.output_parsers import StrOutputParser\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# USER_PROMPT=\"Generiere mir einen Post für die PubTour am 16. Oktober\"\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# result = chain.invoke(\"Generiere mir einen Post für die PubTour am 16. Oktober\")\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# print(result)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m result = \u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGeneriere mir einen Post für die PubTour am 16. Oktober\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGeneriere mir einen Post für die PubTour am 16. Oktober\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m#result = chain.invoke(user_prompt)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amuel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3244\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3242\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3243\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3244\u001b[39m         input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3245\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3246\u001b[39m         input_ = context.run(step.invoke, input_, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amuel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\runnables\\base.py:4001\u001b[39m, in \u001b[36mRunnableParallel.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3996\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m   3997\u001b[39m         futures = [\n\u001b[32m   3998\u001b[39m             executor.submit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[32m   3999\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps.items()\n\u001b[32m   4000\u001b[39m         ]\n\u001b[32m-> \u001b[39m\u001b[32m4001\u001b[39m         output = {key: \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[32m   4002\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   4003\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amuel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amuel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amuel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\thread.py:59\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amuel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3985\u001b[39m, in \u001b[36mRunnableParallel.invoke.<locals>._invoke_step\u001b[39m\u001b[34m(step, input_, config, key)\u001b[39m\n\u001b[32m   3979\u001b[39m child_config = patch_config(\n\u001b[32m   3980\u001b[39m     config,\n\u001b[32m   3981\u001b[39m     \u001b[38;5;66;03m# mark each step as a child run\u001b[39;00m\n\u001b[32m   3982\u001b[39m     callbacks=run_manager.get_child(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmap:key:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m),\n\u001b[32m   3983\u001b[39m )\n\u001b[32m   3984\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m-> \u001b[39m\u001b[32m3985\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3986\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3987\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3988\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchild_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3989\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amuel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\retrievers.py:263\u001b[39m, in \u001b[36mBaseRetriever.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    261\u001b[39m kwargs_ = kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._new_arg_supported:\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs_\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    267\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._get_relevant_documents(\u001b[38;5;28minput\u001b[39m, **kwargs_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amuel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:1067\u001b[39m, in \u001b[36mVectorStoreRetriever._get_relevant_documents\u001b[39m\u001b[34m(self, query, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1065\u001b[39m kwargs_ = \u001b[38;5;28mself\u001b[39m.search_kwargs | kwargs\n\u001b[32m   1066\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.search_type == \u001b[33m\"\u001b[39m\u001b[33msimilarity\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1067\u001b[39m     docs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvectorstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1068\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.search_type == \u001b[33m\"\u001b[39m\u001b[33msimilarity_score_threshold\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1069\u001b[39m     docs_and_similarities = (\n\u001b[32m   1070\u001b[39m         \u001b[38;5;28mself\u001b[39m.vectorstore.similarity_search_with_relevance_scores(\n\u001b[32m   1071\u001b[39m             query, **kwargs_\n\u001b[32m   1072\u001b[39m         )\n\u001b[32m   1073\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amuel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:643\u001b[39m, in \u001b[36mFAISS.similarity_search\u001b[39m\u001b[34m(self, query, k, filter, fetch_k, **kwargs)\u001b[39m\n\u001b[32m    623\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msimilarity_search\u001b[39m(\n\u001b[32m    624\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    625\u001b[39m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    629\u001b[39m     **kwargs: Any,\n\u001b[32m    630\u001b[39m ) -> List[Document]:\n\u001b[32m    631\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return docs most similar to query.\u001b[39;00m\n\u001b[32m    632\u001b[39m \n\u001b[32m    633\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    641\u001b[39m \u001b[33;03m        List of Documents most similar to the query.\u001b[39;00m\n\u001b[32m    642\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m     docs_and_scores = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msimilarity_search_with_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    644\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_k\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfetch_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    646\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m docs_and_scores]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amuel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:515\u001b[39m, in \u001b[36mFAISS.similarity_search_with_score\u001b[39m\u001b[34m(self, query, k, filter, fetch_k, **kwargs)\u001b[39m\n\u001b[32m    491\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msimilarity_search_with_score\u001b[39m(\n\u001b[32m    492\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    493\u001b[39m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    497\u001b[39m     **kwargs: Any,\n\u001b[32m    498\u001b[39m ) -> List[Tuple[Document, \u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[32m    499\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return docs most similar to query.\u001b[39;00m\n\u001b[32m    500\u001b[39m \n\u001b[32m    501\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    513\u001b[39m \u001b[33;03m        L2 distance in float. Lower score represents more similarity.\u001b[39;00m\n\u001b[32m    514\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m515\u001b[39m     embedding = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    516\u001b[39m     docs = \u001b[38;5;28mself\u001b[39m.similarity_search_with_score_by_vector(\n\u001b[32m    517\u001b[39m         embedding,\n\u001b[32m    518\u001b[39m         k,\n\u001b[32m   (...)\u001b[39m\u001b[32m    521\u001b[39m         **kwargs,\n\u001b[32m    522\u001b[39m     )\n\u001b[32m    523\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m docs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amuel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:266\u001b[39m, in \u001b[36mFAISS._embed_query\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_embed_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) -> List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    265\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.embedding_function, Embeddings):\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    267\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    268\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.embedding_function(text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amuel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_community\\embeddings\\huggingface.py:130\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.embed_query\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membed_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) -> List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    122\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute query embeddings using a HuggingFace transformer model.\u001b[39;00m\n\u001b[32m    123\u001b[39m \n\u001b[32m    124\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    128\u001b[39m \u001b[33;03m        Embeddings for the text.\u001b[39;00m\n\u001b[32m    129\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amuel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_community\\embeddings\\huggingface.py:109\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute doc embeddings using a HuggingFace transformer model.\u001b[39;00m\n\u001b[32m    100\u001b[39m \n\u001b[32m    101\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    105\u001b[39m \u001b[33;03m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m texts = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.multi_process:\n\u001b[32m    111\u001b[39m     pool = \u001b[38;5;28mself\u001b[39m.client.start_multi_process_pool()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\amuel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_community\\embeddings\\huggingface.py:109\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.embed_documents.<locals>.<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute doc embeddings using a HuggingFace transformer model.\u001b[39;00m\n\u001b[32m    100\u001b[39m \n\u001b[32m    101\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    105\u001b[39m \u001b[33;03m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m texts = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m), texts))\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.multi_process:\n\u001b[32m    111\u001b[39m     pool = \u001b[38;5;28mself\u001b[39m.client.start_multi_process_pool()\n",
      "\u001b[31mAttributeError\u001b[39m: 'dict' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# USER_PROMPT=\"Generiere mir einen Post für die PubTour am 16. Oktober\"\n",
    "\n",
    "# result = chain.invoke(\"Generiere mir einen Post für die PubTour am 16. Oktober\")\n",
    "# print(result)\n",
    "\n",
    "result = chain.invoke({\"question\": \"Generiere mir einen Post für die PubTour am 16. Oktober\", \"text\": \"Generiere mir einen Post für die PubTour am 16. Oktober\"})\n",
    "print(result)\n",
    "\n",
    "#result = chain.invoke(user_prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=56a0a349-7f2e-43e5-8d52-5ded467f6e9c' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote_notebook_id": "b03039a6aad547a39dea08ca00c7302d",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
